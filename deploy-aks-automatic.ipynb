{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54acd27e",
   "metadata": {},
   "source": [
    "# AKS Automatic + MCP Weather Server Deployment Walkthrough\n",
    "\n",
    "This notebook orchestrates deployment of the AKS Automatic infrastructure (defined in [`main.bicep`](main.bicep)) and publishes the MCP Weather Server (located in [`mcp-weather-server/src/index.ts`](mcp-weather-server/src/index.ts)) to the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf409755",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Azure CLI authenticated: `az login`\n",
    "- Docker daemon running, logged into your Azure Container Registry (ACR)\n",
    "- Bicep CLI installed (comes with Azure CLI 2.50+)\n",
    "- Kubernetes CLI (`kubectl`) installed\n",
    "- Notebook kernel with network and shell access (e.g., Azure ML compute, local dev machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c46008",
   "metadata": {},
   "source": [
    "## 0️⃣ Initialize Notebook Variables\n",
    "Before running the workflow, review these defaults and adjust them to match your Azure subscription, naming conventions, and endpoint URLs. Values fall back to environment variables when present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b415d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dataclasses import asdict, dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class NotebookConfig:\n",
    "    resource_group: str = \"rg-aks-automatic\"\n",
    "    location: str = \"eastus\"\n",
    "    aks_deployment_name: str = \"aks-automatic\"\n",
    "    acr_name: str = \"<your-registry>\"\n",
    "    mcp_backend_url: str = \"https://<ingress-or-load-balancer-for-mcp>\"\n",
    "    apim_deployment_name: str = \"apim-mcp\"\n",
    "    azure_ai_project_endpoint: str = \"https://<region>.api.azureml.ms\"\n",
    "    azure_ai_project_id: str = \"<project-guid>\"\n",
    "    azure_ai_resource_id: str = \"/subscriptions/<sub-id>/resourceGroups/<rg>/providers/Microsoft.MachineLearningServices/workspaces/<workspace>\"\n",
    "    azure_openai_deployment: str = \"gpt-4_1\"\n",
    "    apim_weather_api_url: str = \"https://<service>.azure-api.net/mcp-weather\"\n",
    "    apim_subscription_key: str = \"<optional-apim-key>\"\n",
    "    aks_cluster_name_override: Optional[str] = None\n",
    "    apim_service_name_override: Optional[str] = None\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls) -> \"NotebookConfig\":\n",
    "        def value(name: str, default: Optional[str] = None) -> Optional[str]:\n",
    "            raw = os.getenv(name)\n",
    "            if raw is None or raw == \"\":\n",
    "                return default\n",
    "            return raw\n",
    "\n",
    "        return cls(\n",
    "            resource_group=value(\"RESOURCE_GROUP\", cls.resource_group),\n",
    "            location=value(\"LOCATION\", cls.location),\n",
    "            aks_deployment_name=value(\"AKS_DEPLOYMENT_NAME\", cls.aks_deployment_name),\n",
    "            acr_name=value(\"ACR_NAME\", cls.acr_name),\n",
    "            mcp_backend_url=value(\"MCP_BACKEND_URL\", cls.mcp_backend_url),\n",
    "            apim_deployment_name=value(\"APIM_DEPLOYMENT_NAME\", cls.apim_deployment_name),\n",
    "            azure_ai_project_endpoint=value(\"AZURE_AI_PROJECT_ENDPOINT\", cls.azure_ai_project_endpoint),\n",
    "            azure_ai_project_id=value(\"AZURE_AI_PROJECT_ID\", cls.azure_ai_project_id),\n",
    "            azure_ai_resource_id=value(\"AZURE_AI_RESOURCE_ID\", cls.azure_ai_resource_id),\n",
    "            azure_openai_deployment=value(\"AZURE_OPENAI_DEPLOYMENT\", cls.azure_openai_deployment),\n",
    "            apim_weather_api_url=value(\"APIM_WEATHER_API_URL\", cls.apim_weather_api_url),\n",
    "            apim_subscription_key=value(\"APIM_SUBSCRIPTION_KEY\", cls.apim_subscription_key),\n",
    "            aks_cluster_name_override=value(\"AKS_CLUSTER_NAME_OVERRIDE\"),\n",
    "            apim_service_name_override=value(\"APIM_SERVICE_NAME_OVERRIDE\"),\n",
    "        )\n",
    "\n",
    "\n",
    "config = NotebookConfig.load()\n",
    "CONFIG = asdict(config)\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "AGENT_DIR = PROJECT_ROOT / \"agents\"\n",
    "AGENT_REQUIREMENTS = AGENT_DIR / \"requirements.txt\"\n",
    "AGENT_SCRIPT = AGENT_DIR / \"create_agent.py\"\n",
    "AGENT_RUN_OUTPUT = AGENT_DIR / \"agent_invoke_response.json\"\n",
    "TEMPLATE_FILE = \"main.bicep\"\n",
    "PARAM_FILE = \"main.bicepparam\"\n",
    "APIM_TEMPLATE_FILE = \"apim-mcp.bicep\"\n",
    "APIM_PARAM_FILE = \"apim-mcp.bicepparam\"\n",
    "AGENT_API_VERSION = \"2024-10-01-preview\"\n",
    "SUMMARY = {}\n",
    "\n",
    "RESOURCE_GROUP = CONFIG[\"resource_group\"]\n",
    "LOCATION = CONFIG[\"location\"]\n",
    "DEPLOYMENT_NAME = CONFIG[\"aks_deployment_name\"]\n",
    "ACR_NAME = CONFIG[\"acr_name\"]\n",
    "MCP_BACKEND_URL = CONFIG[\"mcp_backend_url\"]\n",
    "APIM_DEPLOYMENT_NAME = CONFIG[\"apim_deployment_name\"]\n",
    "AZURE_AI_PROJECT_ENDPOINT = CONFIG[\"azure_ai_project_endpoint\"]\n",
    "AZURE_AI_PROJECT_ID = CONFIG[\"azure_ai_project_id\"]\n",
    "AZURE_AI_RESOURCE_ID = CONFIG[\"azure_ai_resource_id\"]\n",
    "AZURE_OPENAI_DEPLOYMENT = CONFIG[\"azure_openai_deployment\"]\n",
    "APIM_WEATHER_API_URL = CONFIG[\"apim_weather_api_url\"]\n",
    "APIM_SUBSCRIPTION_KEY = CONFIG[\"apim_subscription_key\"]\n",
    "AKS_CLUSTER_NAME_OVERRIDE = CONFIG.get(\"aks_cluster_name_override\") or None\n",
    "APIM_SERVICE_NAME_OVERRIDE = CONFIG.get(\"apim_service_name_override\") or None\n",
    "IMAGE_NAME = f\"{ACR_NAME}.azurecr.io/mcp-weather-server:latest\"\n",
    "\n",
    "print(\"Notebook configuration:\\n\")\n",
    "for key, value in CONFIG.items():\n",
    "    display = value if value not in (None, \"\") else \"[not set]\"\n",
    "    if key.endswith(\"_key\") and display not in (\"[not set]\", None, \"\") and \"<\" not in str(display):\n",
    "        display = f\"****{str(display)[-4:]}\"\n",
    "    print(f\"  {key}: {display}\")\n",
    "\n",
    "print(\"\\nArtifacts:\")\n",
    "print(f\"  project_root: {PROJECT_ROOT}\")\n",
    "print(f\"  agents_dir: {AGENT_DIR}\")\n",
    "print(f\"  template_file: {TEMPLATE_FILE}\")\n",
    "print(f\"  container_image: {IMAGE_NAME}\")\n",
    "\n",
    "print(\"\\n✅ Notebook initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "from typing import List, Optional, Sequence\n",
    "\n",
    "import requests\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "\n",
    "def get_access_token(scope: str = \"https://cognitiveservices.azure.com/.default\") -> str:\n",
    "    \"\"\"Acquire an Azure AD token for the specified scope.\"\"\"\n",
    "    credential = DefaultAzureCredential()\n",
    "    token = credential.get_token(scope)\n",
    "    return token.token\n",
    "\n",
    "\n",
    "def run_command(command: Sequence[str], *, cwd: Optional[str] = None, capture_output: bool = False, text: bool = True, env: Optional[dict] = None) -> subprocess.CompletedProcess:\n",
    "    \"\"\"Run a CLI command with consistent logging.\"\"\"\n",
    "    printable = \" \".join(command)\n",
    "    print(f\"$ {printable}\")\n",
    "    return subprocess.run(command, cwd=cwd, env=env, check=True, capture_output=capture_output, text=text)\n",
    "\n",
    "\n",
    "def deploy_group_bicep(deployment_name: str, resource_group: str, template_file: str, parameter_file: str, extra_parameters: Optional[List[str]] = None) -> dict:\n",
    "    \"\"\"Deploy a Bicep template to a resource group and return the deployment outputs.\"\"\"\n",
    "    args = [\n",
    "        \"az\", \"deployment\", \"group\", \"create\",\n",
    "        \"--name\", deployment_name,\n",
    "        \"--resource-group\", resource_group,\n",
    "        \"--template-file\", template_file,\n",
    "        \"--parameters\", f\"@{parameter_file}\",\n",
    "        \"--output\", \"json\",\n",
    "    ]\n",
    "    if extra_parameters:\n",
    "        args.extend(extra_parameters)\n",
    "    completed = run_command(args, capture_output=True)\n",
    "    return json.loads(completed.stdout)\n",
    "\n",
    "print(\"Loaded core libraries and helper utilities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0416b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Ensure the resource group exists\n",
    "\n",
    "run_command([\n",
    "    \"az\", \"group\", \"create\",\n",
    "    \"--name\", RESOURCE_GROUP,\n",
    "    \"--location\", LOCATION,\n",
    "    \"--output\", \"none\",\n",
    "])\n",
    "\n",
    "print(\"✔️ Resource group ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b268c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Deploy AKS Automatic using Bicep\n",
    "\n",
    "deployment_result = deploy_group_bicep(\n",
    "    DEPLOYMENT_NAME,\n",
    "    RESOURCE_GROUP,\n",
    "    TEMPLATE_FILE,\n",
    "    PARAM_FILE,\n",
    " )\n",
    "\n",
    "deployment_outputs = deployment_result.get(\"properties\", {}).get(\"outputs\", {})\n",
    "\n",
    "print(json.dumps(deployment_outputs, indent=2))\n",
    "\n",
    "print(\"✔️ AKS deployment completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Capture key outputs for later steps\n",
    "\n",
    "cluster_name = AKS_CLUSTER_NAME_OVERRIDE or deployment_outputs.get(\"clusterName\", {}).get(\"value\")\n",
    "workspace_id = deployment_outputs.get(\"workspaceId\", {}).get(\"value\")\n",
    "cluster_id = deployment_outputs.get(\"clusterId\", {}).get(\"value\") if deployment_outputs else None\n",
    "print(f\"Cluster name: {cluster_name}\")\n",
    "print(f\"Log Analytics workspace: {workspace_id}\")\n",
    "if not cluster_name:\n",
    "    raise ValueError(\"clusterName output missing; check your deployment parameters and outputs.\")\n",
    "SUMMARY.update({\n",
    "    \"aks_cluster_name\": cluster_name,\n",
    "    \"aks_cluster_id\": cluster_id,\n",
    "    \"log_analytics_workspace\": workspace_id,\n",
    "})\n",
    "print(\"✔️ Captured AKS outputs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Attach ACR permissions to the AKS cluster\n",
    "\n",
    "run_command([\n",
    "    \"az\", \"aks\", \"update\",\n",
    "    \"--resource-group\", RESOURCE_GROUP,\n",
    "    \"--name\", cluster_name,\n",
    "    \"--attach-acr\", ACR_NAME,\n",
    "])\n",
    "\n",
    "print(\"✔️ AKS cluster now has pull permissions for the ACR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f64826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge AKS credentials into local kubeconfig\n",
    "\n",
    "run_command([\n",
    "    \"az\", \"aks\", \"get-credentials\",\n",
    "    \"--resource-group\", RESOURCE_GROUP,\n",
    "    \"--name\", cluster_name,\n",
    "    \"--overwrite-existing\",\n",
    "])\n",
    "\n",
    "print(f\"✔️ Kubeconfig updated for {cluster_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d634d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Build and push MCP Weather Server image\n",
    "\n",
    "server_dir = PROJECT_ROOT / \"mcp-weather-server\"\n",
    "run_command([\"npm\", \"install\"], cwd=str(server_dir))\n",
    "run_command([\"npm\", \"run\", \"build\"], cwd=str(server_dir))\n",
    "run_command([\"docker\", \"build\", \"-t\", IMAGE_NAME, \".\"], cwd=str(server_dir))\n",
    "run_command([\"az\", \"acr\", \"login\", \"--name\", ACR_NAME])\n",
    "run_command([\"docker\", \"push\", IMAGE_NAME])\n",
    "print(\"✔️ Container image built and pushed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Deploy MCP Weather Server workload to AKS\n",
    "\n",
    "manifest_path = PROJECT_ROOT / \"k8s\" / \"mcp-weather.yaml\"\n",
    "manifest_text = manifest_path.read_text()\n",
    "patched_manifest = manifest_text.replace(\"<your-registry>.azurecr.io/mcp-weather-server:latest\", IMAGE_NAME)\n",
    "with tempfile.NamedTemporaryFile(\"w\", suffix=\".yaml\", delete=False) as temp_manifest:\n",
    "    temp_manifest.write(patched_manifest)\n",
    "    rendered_manifest_path = temp_manifest.name\n",
    "run_command([\"kubectl\", \"apply\", \"-f\", rendered_manifest_path])\n",
    "print(\"✔️ MCP Weather workload applied to AKS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b779f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Verify rollout\n",
    "\n",
    "run_command([\"kubectl\", \"get\", \"pods\", \"-l\", \"app=mcp-weather-server\"])\n",
    "try:\n",
    "    run_command([\"kubectl\", \"logs\", \"deploy/mcp-weather-server\"])\n",
    "except subprocess.CalledProcessError as exc:\n",
    "    print(f\"kubectl logs failed: {exc}. Continuing.\")\n",
    "print(\"✔️ Reviewed pod status and logs (see output above).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed524c",
   "metadata": {},
   "source": [
    "## Publish MCP Weather through API Management\n",
    "Set the MCP service endpoint (`MCP_BACKEND_URL`) above to an address reachable by API Management (for example, an Azure Application Gateway, load balancer IP, or ingress hostname that fronts the MCP Weather service). Then run the following steps to provision API Management and wire it to the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Deploy API Management for MCP Weather\n",
    "\n",
    "if \"<ingress\" in MCP_BACKEND_URL or MCP_BACKEND_URL.endswith(\"for-mcp>\"):\n",
    "    raise ValueError(\"Set MCP_BACKEND_URL to the live endpoint that fronts the MCP Weather service before deploying APIM.\")\n",
    "\n",
    "apim_deploy = deploy_group_bicep(\n",
    "    APIM_DEPLOYMENT_NAME,\n",
    "    RESOURCE_GROUP,\n",
    "    APIM_TEMPLATE_FILE,\n",
    "    APIM_PARAM_FILE,\n",
    "    extra_parameters=[\"--parameters\", f\"mcpBackendUrl={MCP_BACKEND_URL}\"],\n",
    ")\n",
    "\n",
    "apim_outputs = apim_deploy.get(\"properties\", {}).get(\"outputs\", {})\n",
    "\n",
    "print(json.dumps(apim_outputs, indent=2))\n",
    "\n",
    "print(\"✔️ API Management deployment completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Summarize API Management endpoints\n",
    "\n",
    "apim_parameters = apim_deploy.get(\"properties\", {}).get(\"parameters\", {})\n",
    "apim_service_name = APIM_SERVICE_NAME_OVERRIDE or apim_parameters.get(\"serviceName\", {}).get(\"value\")\n",
    "print(f\"APIM service name: {apim_service_name}\")\n",
    "print(\"Gateway URL:\", apim_outputs.get(\"gatewayUrl\", {}).get(\"value\"))\n",
    "print(\"Developer portal URL:\", apim_outputs.get(\"developerPortalUrl\", {}).get(\"value\"))\n",
    "print(\"Weather API invoke URL:\", apim_outputs.get(\"apiInvokeUrl\", {}).get(\"value\"))\n",
    "print(\"✔️ Recorded API Management endpoints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Store APIM outputs for later steps\n",
    "\n",
    "if not apim_outputs:\n",
    "    raise ValueError(\"APIM outputs unavailable. Run Step 9 to deploy API Management first.\")\n",
    "\n",
    "apim_gateway_url = apim_outputs.get(\"gatewayUrl\", {}).get(\"value\")\n",
    "apim_developer_portal = apim_outputs.get(\"developerPortalUrl\", {}).get(\"value\")\n",
    "apim_weather_api_url = apim_outputs.get(\"apiInvokeUrl\", {}).get(\"value\")\n",
    "\n",
    "if apim_weather_api_url:\n",
    "    APIM_WEATHER_API_URL = apim_weather_api_url\n",
    "    os.environ[\"APIM_WEATHER_API_URL\"] = APIM_WEATHER_API_URL\n",
    "    SUMMARY[\"apim_weather_api_url\"] = APIM_WEATHER_API_URL\n",
    "    print(f\"Stored APIM weather API URL: {APIM_WEATHER_API_URL}\")\n",
    "else:\n",
    "    print(\"APIM weather API URL not found in outputs; ensure apim-mcp.bicep succeeded.\")\n",
    "\n",
    "if apim_gateway_url:\n",
    "    SUMMARY[\"apim_gateway_url\"] = apim_gateway_url\n",
    "    print(f\"APIM gateway URL: {apim_gateway_url}\")\n",
    "if apim_developer_portal:\n",
    "    SUMMARY[\"apim_developer_portal\"] = apim_developer_portal\n",
    "    print(f\"APIM developer portal: {apim_developer_portal}\")\n",
    "print(\"✔️ APIM outputs cached for downstream steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26974126",
   "metadata": {},
   "source": [
    "## Create Azure AI Foundry Agent\n",
    "Provide Azure AI Foundry project details in the configuration cell (Cell 3) or export them as environment variables before running the steps below. The agent script will call the Azure AI Projects Agents API to register a GPT-4.1 agent that invokes the MCP Weather API via API Management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Install agent dependencies\n",
    "\n",
    "if not AGENT_REQUIREMENTS.exists():\n",
    "    raise FileNotFoundError(f\"Missing requirements file at {AGENT_REQUIREMENTS}.\")\n",
    "\n",
    "run_command([\"python\", \"-m\", \"pip\", \"install\", \"-r\", str(AGENT_REQUIREMENTS)])\n",
    "\n",
    "print(\"✔️ Agent dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037bc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Create GPT-4.1 agent in Azure AI Foundry\n",
    "\n",
    "placeholders = [AZURE_AI_PROJECT_ENDPOINT, AZURE_AI_PROJECT_ID, AZURE_AI_RESOURCE_ID, AZURE_OPENAI_DEPLOYMENT, APIM_WEATHER_API_URL]\n",
    "if any(token.startswith(\"http\") and \"<\" in token for token in placeholders) or any(\"<\" in token for token in placeholders):\n",
    "    raise ValueError(\"Replace Azure AI / APIM configuration placeholders in the configuration cell or set real values via environment variables before running this step.\")\n",
    "\n",
    "if not AGENT_SCRIPT.exists():\n",
    "    raise FileNotFoundError(f\"Agent script missing at {AGENT_SCRIPT}.\")\n",
    "\n",
    "agent_env = os.environ.copy()\n",
    "agent_env.update({\n",
    "    \"AZURE_AI_PROJECT_ENDPOINT\": AZURE_AI_PROJECT_ENDPOINT,\n",
    "    \"AZURE_AI_PROJECT_ID\": AZURE_AI_PROJECT_ID,\n",
    "    \"AZURE_AI_RESOURCE_ID\": AZURE_AI_RESOURCE_ID,\n",
    "    \"AZURE_OPENAI_DEPLOYMENT\": AZURE_OPENAI_DEPLOYMENT,\n",
    "    \"APIM_WEATHER_API_URL\": APIM_WEATHER_API_URL,\n",
    "})\n",
    "if APIM_SUBSCRIPTION_KEY and \"<\" not in APIM_SUBSCRIPTION_KEY:\n",
    "    agent_env[\"APIM_SUBSCRIPTION_KEY\"] = APIM_SUBSCRIPTION_KEY\n",
    "\n",
    "run_command([\"python\", AGENT_SCRIPT.name], cwd=str(AGENT_DIR), env=agent_env)\n",
    "\n",
    "agent_response_file = AGENT_DIR / \"agent_response.json\"\n",
    "if agent_response_file.exists():\n",
    "    agent_payload = json.loads(agent_response_file.read_text())\n",
    "    agent_identifier = agent_payload.get(\"id\") or agent_payload.get(\"name\") or agent_payload.get(\"agentId\")\n",
    "    SUMMARY[\"agent_id\"] = agent_identifier\n",
    "    print(f\"Agent ID: {agent_identifier}\")\n",
    "else:\n",
    "    print(\"agent_response.json not found; ensure the helper script completed successfully.\")\n",
    "\n",
    "print(\"✔️ Agent creation request submitted. Inspect agents/agent_response.json for additional metadata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018b4d9",
   "metadata": {},
   "source": [
    "## Test the Azure AI Foundry Agent\n",
    "Use the agent identifier returned in `agents/agent_response.json` to send a test weather query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Invoke the agent with a sample weather request\n",
    "\n",
    "agent_response_path = AGENT_DIR / \"agent_response.json\"\n",
    "if not agent_response_path.exists():\n",
    "    raise FileNotFoundError(\"Run Step 13 first so agent_response.json is available.\")\n",
    "\n",
    "agent_data = json.loads(agent_response_path.read_text())\n",
    "agent_id = agent_data.get(\"id\") or agent_data.get(\"name\") or agent_data.get(\"agentId\")\n",
    "if not agent_id:\n",
    "    raise ValueError(\"Agent identifier not found in agent_response.json. Inspect the file and update this cell if necessary.\")\n",
    "\n",
    "for value in [AZURE_AI_PROJECT_ENDPOINT, AZURE_AI_PROJECT_ID, AZURE_AI_RESOURCE_ID]:\n",
    "    if value is None or \"<\" in value:\n",
    "        raise ValueError(\"Provide valid Azure AI configuration values (configuration cell or environment variables) before invoking the agent.\")\n",
    "\n",
    "token = get_access_token()\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"ai-resource-id\": AZURE_AI_RESOURCE_ID,\n",
    "    \"ai-project-id\": AZURE_AI_PROJECT_ID,\n",
    "}\n",
    "\n",
    "invoke_url = f\"{AZURE_AI_PROJECT_ENDPOINT}/openai/agents/{agent_id}:invoke?api-version={AGENT_API_VERSION}\"\n",
    "payload = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather like today in Seattle?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(invoke_url, headers=headers, data=json.dumps(payload), timeout=60)\n",
    "response.raise_for_status()\n",
    "invoke_result = response.json()\n",
    "AGENT_RUN_OUTPUT.write_text(json.dumps(invoke_result, indent=2))\n",
    "\n",
    "assistant_reply = None\n",
    "output = invoke_result.get(\"output\") or invoke_result.get(\"result\")\n",
    "if isinstance(output, list):\n",
    "    for item in output:\n",
    "        blocks = item.get(\"content\") if isinstance(item, dict) else None\n",
    "        if isinstance(blocks, list):\n",
    "            for block in blocks:\n",
    "                if isinstance(block, dict):\n",
    "                    if block.get(\"type\") == \"text\":\n",
    "                        assistant_reply = block.get(\"text\") or block.get(\"value\")\n",
    "                    elif \"text\" in block and isinstance(block[\"text\"], dict):\n",
    "                        assistant_reply = block[\"text\"].get(\"value\")\n",
    "                if assistant_reply:\n",
    "                    break\n",
    "        elif isinstance(blocks, str):\n",
    "            assistant_reply = blocks\n",
    "        if assistant_reply:\n",
    "            break\n",
    "elif isinstance(output, dict):\n",
    "    assistant_reply = output.get(\"message\") or output.get(\"text\")\n",
    "\n",
    "SUMMARY[\"agent_invoke_response_file\"] = str(AGENT_RUN_OUTPUT)\n",
    "if assistant_reply:\n",
    "    SUMMARY[\"agent_reply\"] = assistant_reply\n",
    "\n",
    "print(f\"Agent invocation response saved to {AGENT_RUN_OUTPUT}\")\n",
    "if assistant_reply:\n",
    "    print(\"\\nAgent reply:\\n\")\n",
    "    print(assistant_reply)\n",
    "else:\n",
    "    print(json.dumps(invoke_result, indent=2))\n",
    "\n",
    "print(\"✔️ Agent invocation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5651221",
   "metadata": {},
   "source": [
    "## Deployment Summary\n",
    "Collected outputs from prior steps for quick reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa93987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display collected outputs for reference\n",
    "for key, value in SUMMARY.items():\n",
    "    if value:\n",
    "        print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key}: [not available]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c6677",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Attach your MCP-compatible Agent to the running pod (sidecar or exec).\n",
    "- Harden networking, RBAC, and secret management for production environments.\n",
    "- Configure API Management products, subscriptions, and policies to suit your consumers.\n",
    "- Extend the notebook with teardown steps (`kubectl delete`, `az group delete`) when you're ready to clean up."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
