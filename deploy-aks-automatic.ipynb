{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54acd27e",
   "metadata": {},
   "source": [
    "# AKS Automatic + MCP Weather Server Deployment Walkthrough\n",
    "\n",
    "This notebook orchestrates deployment of the AKS Automatic infrastructure (defined in [`main.bicep`](main.bicep)) and publishes the MCP Weather Server (located in [`mcp-weather-server/src/index.ts`](mcp-weather-server/src/index.ts)) to the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf409755",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Azure CLI authenticated: `az login`\n",
    "- Docker daemon running, logged into your Azure Container Registry (ACR)\n",
    "- Bicep CLI installed (comes with Azure CLI 2.50+)\n",
    "- Kubernetes CLI (`kubectl`) installed\n",
    "- Notebook kernel with network and shell access (e.g., Azure ML compute, local dev machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "from typing import Optional\n",
    "import requests\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# --- Configuration ---\n",
    "RESOURCE_GROUP = \"rg-aks-automatic\"\n",
    "LOCATION = \"eastus\"\n",
    "DEPLOYMENT_NAME = \"aks-automatic\"\n",
    "TEMPLATE_FILE = \"main.bicep\"\n",
    "PARAM_FILE = \"main.bicepparam\"\n",
    "ACR_NAME = \"<your-registry>\"  # e.g. myregistry\n",
    "AKS_CLUSTER_NAME_OVERRIDE = None  # Optional manual override if you set a different clusterName in parameters\n",
    "IMAGE_NAME = f\"{ACR_NAME}.azurecr.io/mcp-weather-server:latest\"\n",
    "PROJECT_ROOT = pathlib.Path.cwd()\n",
    "\n",
    "APIM_DEPLOYMENT_NAME = \"apim-mcp\"\n",
    "APIM_TEMPLATE_FILE = \"apim-mcp.bicep\"\n",
    "APIM_PARAM_FILE = \"apim-mcp.bicepparam\"\n",
    "APIM_SERVICE_NAME_OVERRIDE = None  # Optional manual override if apim-mcp.bicepparam differs\n",
    "MCP_BACKEND_URL = \"https://<ingress-or-load-balancer-for-mcp>\"\n",
    "\n",
    "AGENT_DIR = PROJECT_ROOT / \"agents\"\n",
    "AGENT_REQUIREMENTS = AGENT_DIR / \"requirements.txt\"\n",
    "AGENT_SCRIPT = AGENT_DIR / \"create_agent.py\"\n",
    "AGENT_RUN_OUTPUT = AGENT_DIR / \"agent_invoke_response.json\"\n",
    "\n",
    "AZURE_AI_PROJECT_ENDPOINT = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\", \"https://<region>.api.azureml.ms\")\n",
    "AZURE_AI_PROJECT_ID = os.getenv(\"AZURE_AI_PROJECT_ID\", \"<project-guid>\")\n",
    "AZURE_AI_RESOURCE_ID = os.getenv(\"AZURE_AI_RESOURCE_ID\", \"/subscriptions/<sub-id>/resourceGroups/<rg>/providers/Microsoft.MachineLearningServices/workspaces/<workspace>\")\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4_1\")\n",
    "APIM_WEATHER_API_URL = os.getenv(\"APIM_WEATHER_API_URL\", \"https://<service>.azure-api.net/mcp-weather\")\n",
    "APIM_SUBSCRIPTION_KEY = os.getenv(\"APIM_SUBSCRIPTION_KEY\", \"<optional-apim-key>\")\n",
    "AGENT_API_VERSION = \"2024-10-01-preview\"\n",
    "AGENT_SCOPE = \"https://cognitiveservices.azure.com/.default\"\n",
    "\n",
    "def get_access_token(scope: str = AGENT_SCOPE) -> str:\n",
    "    credential = DefaultAzureCredential()\n",
    "    token = credential.get_token(scope)\n",
    "    return token.token\n",
    "\n",
    "print(f\"Resource group: {RESOURCE_GROUP}\")\n",
    "print(f\"AKS deployment name: {DEPLOYMENT_NAME}\")\n",
    "print(f\"ACR: {ACR_NAME}\")\n",
    "print(f\"Image: {IMAGE_NAME}\")\n",
    "print(f\"APIM deployment name: {APIM_DEPLOYMENT_NAME}\")\n",
    "print(f\"Backend URL for APIM: {MCP_BACKEND_URL}\")\n",
    "print(f\"Agent script path: {AGENT_SCRIPT}\")\n",
    "print(f\"Azure AI project endpoint: {AZURE_AI_PROJECT_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0416b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Ensure the resource group exists\n",
    "subprocess.run([\"az\", \"group\", \"create\",\n",
    "                \"--name\", RESOURCE_GROUP,\n",
    "                \"--location\", LOCATION,\n",
    "                \"--output\", \"none\"], check=True)\n",
    "print(\"Resource group ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b268c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Deploy AKS Automatic using Bicep\n",
    "deploy = subprocess.run([\"az\", \"deployment\", \"group\", \"create\",\n",
    "                           \"--name\", DEPLOYMENT_NAME,\n",
    "                           \"--resource-group\", RESOURCE_GROUP,\n",
    "                           \"--template-file\", TEMPLATE_FILE,\n",
    "                           \"--parameters\", f\"@{PARAM_FILE}\",\n",
    "                           \"--output\", \"json\"],\n",
    "                          check=True, capture_output=True, text=True)\n",
    "deployment_result = json.loads(deploy.stdout)\n",
    "deployment_outputs = deployment_result.get(\"properties\", {}).get(\"outputs\", {})\n",
    "print(json.dumps(deployment_outputs, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Capture key outputs for later steps\n",
    "cluster_name = AKS_CLUSTER_NAME_OVERRIDE or deployment_outputs.get(\"clusterName\", {}).get(\"value\")\n",
    "workspace_id = deployment_outputs.get(\"workspaceId\", {}).get(\"value\")\n",
    "print(f\"Cluster name: {cluster_name}\")\n",
    "print(f\"Log Analytics workspace: {workspace_id}\")\n",
    "if not cluster_name:\n",
    "    raise ValueError(\"clusterName output missing; check your deployment parameters and outputs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Attach ACR permissions to the AKS cluster\n",
    "subprocess.run([\"az\", \"aks\", \"update\",\n",
    "                \"--resource-group\", RESOURCE_GROUP,\n",
    "                \"--name\", cluster_name,\n",
    "                \"--attach-acr\", ACR_NAME], check=True)\n",
    "print(\"AKS cluster now has pull permissions for the ACR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f64826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Merge AKS credentials into local kubeconfig\n",
    "subprocess.run([\"az\", \"aks\", \"get-credentials\",\n",
    "                \"--resource-group\", RESOURCE_GROUP,\n",
    "                \"--name\", cluster_name,\n",
    "                \"--overwrite-existing\"], check=True)\n",
    "print(f\"Kubeconfig updated for {cluster_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d634d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Build and push MCP Weather Server image\n",
    "server_dir = PROJECT_ROOT / \"mcp-weather-server\"\n",
    "subprocess.run([\"npm\", \"install\"], cwd=server_dir, check=True)\n",
    "subprocess.run([\"npm\", \"run\", \"build\"], cwd=server_dir, check=True)\n",
    "subprocess.run([\"docker\", \"build\", \"-t\", IMAGE_NAME, \".\"], cwd=server_dir, check=True)\n",
    "subprocess.run([\"az\", \"acr\", \"login\", \"--name\", ACR_NAME], check=True)\n",
    "subprocess.run([\"docker\", \"push\", IMAGE_NAME], check=True)\n",
    "print(\"Container image pushed to ACR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Deploy MCP Weather Server workload to AKS\n",
    "manifest_path = PROJECT_ROOT / \"k8s\" / \"mcp-weather.yaml\"\n",
    "manifest_text = manifest_path.read_text()\n",
    "patched_manifest = manifest_text.replace(\"<your-registry>.azurecr.io/mcp-weather-server:latest\", IMAGE_NAME)\n",
    "with tempfile.NamedTemporaryFile('w', suffix='.yaml', delete=False) as temp_manifest:\n",
    "    temp_manifest.write(patched_manifest)\n",
    "    rendered_manifest_path = temp_manifest.name\n",
    "subprocess.run([\"kubectl\", \"apply\", \"-f\", rendered_manifest_path], check=True)\n",
    "print(\"MCP Weather Server manifest applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b779f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Verify rollout\n",
    "subprocess.run([\"kubectl\", \"get\", \"pods\", \"-l\", \"app=mcp-weather-server\"], check=True)\n",
    "subprocess.run([\"kubectl\", \"logs\", \"deploy/mcp-weather-server\"], check=False)\n",
    "print(\"Review pod status and logs above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed524c",
   "metadata": {},
   "source": [
    "## Publish MCP Weather through API Management\n",
    "Set the MCP service endpoint (`MCP_BACKEND_URL`) above to an address reachable by API Management (for example, an Azure Application Gateway, load balancer IP, or ingress hostname that fronts the MCP Weather service). Then run the following steps to provision API Management and wire it to the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Deploy API Management for MCP Weather\n",
    "if \"<ingress\" in MCP_BACKEND_URL or MCP_BACKEND_URL.endswith(\"for-mcp>\"):\n",
    "    raise ValueError(\"Set MCP_BACKEND_URL to the live endpoint that fronts the MCP Weather service before deploying APIM.\")\n",
    "\n",
    "apim_deploy = subprocess.run([\"az\", \"deployment\", \"group\", \"create\",\n",
    "                              \"--name\", APIM_DEPLOYMENT_NAME,\n",
    "                              \"--resource-group\", RESOURCE_GROUP,\n",
    "                              \"--template-file\", APIM_TEMPLATE_FILE,\n",
    "                              \"--parameters\", f\"@{APIM_PARAM_FILE}\",\n",
    "                              \"--parameters\", f\"mcpBackendUrl={MCP_BACKEND_URL}\",\n",
    "                              \"--output\", \"json\"],\n",
    "                             check=True, capture_output=True, text=True)\n",
    "\n",
    "apim_result = json.loads(apim_deploy.stdout)\n",
    "apim_outputs = apim_result.get(\"properties\", {}).get(\"outputs\", {})\n",
    "print(json.dumps(apim_outputs, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Summarize API Management endpoints\n",
    "apim_parameters = apim_result.get(\"properties\", {}).get(\"parameters\", {})\n",
    "apim_service_name = APIM_SERVICE_NAME_OVERRIDE or apim_parameters.get(\"serviceName\", {}).get(\"value\")\n",
    "print(f\"APIM service name: {apim_service_name}\")\n",
    "print(\"Gateway URL:\", apim_outputs.get(\"gatewayUrl\", {}).get(\"value\"))\n",
    "print(\"Developer portal URL:\", apim_outputs.get(\"developerPortalUrl\", {}).get(\"value\"))\n",
    "print(\"Weather API invoke URL:\", apim_outputs.get(\"apiInvokeUrl\", {}).get(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Store APIM outputs for later steps\n",
    "if not apim_outputs:\n",
    "    raise ValueError(\"APIM outputs unavailable. Run Step 9 to deploy API Management first.\")\n",
    "\n",
    "apim_gateway_url = apim_outputs.get(\"gatewayUrl\", {}).get(\"value\")\n",
    "apim_developer_portal = apim_outputs.get(\"developerPortalUrl\", {}).get(\"value\")\n",
    "apim_weather_api_url = apim_outputs.get(\"apiInvokeUrl\", {}).get(\"value\")\n",
    "\n",
    "if apim_weather_api_url:\n",
    "    APIM_WEATHER_API_URL = apim_weather_api_url\n",
    "    os.environ[\"APIM_WEATHER_API_URL\"] = APIM_WEATHER_API_URL\n",
    "    print(f\"Stored APIM weather API URL: {APIM_WEATHER_API_URL}\")\n",
    "else:\n",
    "    print(\"APIM weather API URL not found in outputs; ensure apim-mcp.bicep succeeded.\")\n",
    "\n",
    "if apim_gateway_url:\n",
    "    print(f\"APIM gateway URL: {apim_gateway_url}\")\n",
    "if apim_developer_portal:\n",
    "    print(f\"APIM developer portal: {apim_developer_portal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26974126",
   "metadata": {},
   "source": [
    "## Create Azure AI Foundry Agent\n",
    "Provide Azure AI Foundry project details in the configuration cell (Cell 3) or export them as environment variables before running the steps below. The agent script will call the Azure AI Projects Agents API to register a GPT-4.1 agent that invokes the MCP Weather API via API Management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Install agent dependencies\n",
    "if not AGENT_REQUIREMENTS.exists():\n",
    "    raise FileNotFoundError(f\"Missing requirements file at {AGENT_REQUIREMENTS}.\")\n",
    "\n",
    "subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"-r\", str(AGENT_REQUIREMENTS)], check=True)\n",
    "\n",
    "print(\"Agent dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037bc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Create GPT-4.1 agent in Azure AI Foundry\n",
    "placeholders = [AZURE_AI_PROJECT_ENDPOINT, AZURE_AI_PROJECT_ID, AZURE_AI_RESOURCE_ID, AZURE_OPENAI_DEPLOYMENT, APIM_WEATHER_API_URL]\n",
    "if any(token.startswith(\"http\") and \"<\" in token for token in placeholders) or any(\"<\" in token for token in placeholders):\n",
    "    raise ValueError(\"Replace Azure AI / APIM configuration placeholders in Cell 3 or set real values via environment variables before running this step.\")\n",
    "\n",
    "if not AGENT_SCRIPT.exists():\n",
    "    raise FileNotFoundError(f\"Agent script missing at {AGENT_SCRIPT}.\")\n",
    "\n",
    "agent_env = os.environ.copy()\n",
    "agent_env.update({\n",
    "    \"AZURE_AI_PROJECT_ENDPOINT\": AZURE_AI_PROJECT_ENDPOINT,\n",
    "    \"AZURE_AI_PROJECT_ID\": AZURE_AI_PROJECT_ID,\n",
    "    \"AZURE_AI_RESOURCE_ID\": AZURE_AI_RESOURCE_ID,\n",
    "    \"AZURE_OPENAI_DEPLOYMENT\": AZURE_OPENAI_DEPLOYMENT,\n",
    "    \"APIM_WEATHER_API_URL\": APIM_WEATHER_API_URL,\n",
    "})\n",
    "if APIM_SUBSCRIPTION_KEY and \"<\" not in APIM_SUBSCRIPTION_KEY:\n",
    "    agent_env[\"APIM_SUBSCRIPTION_KEY\"] = APIM_SUBSCRIPTION_KEY\n",
    "\n",
    "subprocess.run([\"python\", str(AGENT_SCRIPT)], cwd=AGENT_DIR, check=True, env=agent_env)\n",
    "\n",
    "print(\"Agent creation request submitted. Inspect agents/agent_response.json for the agent identifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018b4d9",
   "metadata": {},
   "source": [
    "## Test the Azure AI Foundry Agent\n",
    "Use the agent identifier returned in `agents/agent_response.json` to send a test weather query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Invoke the agent with a sample weather request\n",
    "agent_response_path = AGENT_DIR / \"agent_response.json\"\n",
    "if not agent_response_path.exists():\n",
    "    raise FileNotFoundError(\"Run Step 13 first so agent_response.json is available.\")\n",
    "\n",
    "agent_data = json.loads(agent_response_path.read_text())\n",
    "agent_id = agent_data.get(\"id\") or agent_data.get(\"name\") or agent_data.get(\"agentId\")\n",
    "if not agent_id:\n",
    "    raise ValueError(\"Agent identifier not found in agent_response.json. Inspect the file and update this cell if necessary.\")\n",
    "\n",
    "for value in [AZURE_AI_PROJECT_ENDPOINT, AZURE_AI_PROJECT_ID, AZURE_AI_RESOURCE_ID]:\n",
    "    if value is None or \"<\" in value:\n",
    "        raise ValueError(\"Provide valid Azure AI configuration values (Cell 3 or environment variables) before invoking the agent.\")\n",
    "\n",
    "token = get_access_token()\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"ai-resource-id\": AZURE_AI_RESOURCE_ID,\n",
    "    \"ai-project-id\": AZURE_AI_PROJECT_ID,\n",
    "}\n",
    "\n",
    "invoke_url = f\"{AZURE_AI_PROJECT_ENDPOINT}/openai/agents/{agent_id}:invoke?api-version={AGENT_API_VERSION}\"\n",
    "payload = {\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather like today in Seattle?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(invoke_url, headers=headers, data=json.dumps(payload), timeout=60)\n",
    "response.raise_for_status()\n",
    "invoke_result = response.json()\n",
    "AGENT_RUN_OUTPUT.write_text(json.dumps(invoke_result, indent=2))\n",
    "\n",
    "assistant_reply = None\n",
    "output = invoke_result.get(\"output\") or invoke_result.get(\"result\")\n",
    "if isinstance(output, list):\n",
    "    for item in output:\n",
    "        blocks = item.get(\"content\") if isinstance(item, dict) else None\n",
    "        if isinstance(blocks, list):\n",
    "            for block in blocks:\n",
    "                if isinstance(block, dict):\n",
    "                    if block.get(\"type\") == \"text\":\n",
    "                        assistant_reply = block.get(\"text\") or block.get(\"value\")\n",
    "                    elif \"text\" in block and isinstance(block[\"text\"], dict):\n",
    "                        assistant_reply = block[\"text\"].get(\"value\")\n",
    "                if assistant_reply:\n",
    "                    break\n",
    "        elif isinstance(blocks, str):\n",
    "            assistant_reply = blocks\n",
    "        if assistant_reply:\n",
    "            break\n",
    "elif isinstance(output, dict):\n",
    "    assistant_reply = output.get(\"message\") or output.get(\"text\")\n",
    "\n",
    "print(f\"Agent invocation response saved to {AGENT_RUN_OUTPUT}\")\n",
    "if assistant_reply:\n",
    "    print(\"\\nAgent reply:\\n\")\n",
    "    print(assistant_reply)\n",
    "else:\n",
    "    print(json.dumps(invoke_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c6677",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Attach your MCP-compatible Agent to the running pod (sidecar or exec).\n",
    "- Harden networking, RBAC, and secret management for production environments.\n",
    "- Configure API Management products, subscriptions, and policies to suit your consumers.\n",
    "- Extend the notebook with teardown steps (`kubectl delete`, `az group delete`) when you're ready to clean up."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
